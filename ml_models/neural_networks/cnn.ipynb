{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "- Input: Images of 2D or 3D dimension\n",
    "- Hidden Layers: Convolutional Layer, Pooling Layer, Fully-Connected Layer (similar to a regular Neural Networks)\n",
    "- These layers are stacked togethre to from the full architecture\n",
    "- For example, we can build a simple CNN for image classification that follows this sequence [Input - Conv - ReLu - Pool - FC]\n",
    "- The input consists of images of 32x32x3 where the depth is just the RGB color channel\n",
    "- The Conv layer computes the dot product between their weights and a small region connected to the input layer. This depends on the number of filters that we use. If we use 12 filters, then the output volume will be 32x32x12.\n",
    "- ReLU applies the elementwise activation function without changing the volume size.\n",
    "- Pool layer downsamples along the spatial dimensions\n",
    "- FC layer compute the class scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Functions Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Example Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-keras\n",
      "  Downloading tensorflow_keras-0.1-py3-none-any.whl.metadata (63 bytes)\n",
      "Downloading tensorflow_keras-0.1-py3-none-any.whl (5.2 kB)\n",
      "Installing collected packages: tensorflow-keras\n",
      "Successfully installed tensorflow-keras-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "(X_train, y_train), (_, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the train set consists of 60,000 images, each with a size of 28x28\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(12,8))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(5):\n",
    "    axes[i].imshow(X_train[i], cmap='gray')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_img = X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_img.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foward Operation\n",
    "\n",
    "Let's do a forward operation where we take the input image, pass it through the convolutional layer with different filters, perform activation ReLU and downsampling through max pooling, to flattening the output to the fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "stride = 2\n",
    "zero_padding = 0\n",
    "num_filters = 3\n",
    "filter_size = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize weights for the filters\n",
    "kernel1 = np.ones((filter_size, filter_size))\n",
    "kernel2 = np.ones((filter_size, filter_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to make sure the filter has the same number of dimensions as the input image\n",
    "kernel1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of output volumn\n",
    "output_size = int((example_img.shape[0] - kernel1.shape[0] + 2*zero_padding)/stride + 1)\n",
    "output_size\n",
    "output1 = np.zeros((output_size, output_size))\n",
    "output2 = np.zeros((output_size, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W0 = kernel1\n",
    "W1 = kernel2\n",
    "W0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1[0][0] = np.sum(example_img[0:filter_size, 0:filter_size]*W0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now perform convolution to generate the first output for the map\n",
    "for i in range(0, output_size, stride):\n",
    "    for j in range(0, output_size, stride):\n",
    "        if i + filter_size <= example_img.shape[0] and i + filter_size <= example_img.shape[1]:\n",
    "            output1[i//stride][j//stride] = np.sum(example_img[i:i+filter_size, j:j+filter_size]*W0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now perform convolution to generate the second output for the map\n",
    "for i in range(0, output_size, stride):\n",
    "    for j in range(0, output_size, stride):\n",
    "        if i + filter_size <= example_img.shape[0] and i + filter_size <= example_img.shape[1]:\n",
    "            output2[i//stride][j//stride] = np.sum(example_img[i:i+filter_size, j:j+filter_size]*W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack two output volumes together to generate the final activation map\n",
    "final_output = np.stack((output1, output2), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14, 2)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now perform ReLU\n",
    "activated_final_output = np.maximum(0, final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14, 2)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activated_final_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7, 2)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now perform pooling to downsample the output volumn\n",
    "pooled_size = int((activated_final_output.shape[0]-2)/2 + 1)\n",
    "pooled_output = np.zeros((pooled_size, pooled_size, activated_final_output.shape[2]))\n",
    "pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, pooled_size, 2):\n",
    "    for j in range(0, pooled_size, 2):\n",
    "        for k in range(0, 2):\n",
    "            if i + 2 <= activated_final_output.shape[0] and j + 2 <= activated_final_output.shape[1]:\n",
    "                pooled_output[i//2][j//2][k] = np.max(activated_final_output[i:i+pooled_size, j:j+pooled_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7, 2)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98,)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten the output\n",
    "flattened_output = pooled_output.flatten()\n",
    "flattened_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOP Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet:\n",
    "    def __init__(self, \n",
    "                 input, \n",
    "                 stride, \n",
    "                 zero_padding, \n",
    "                 size,\n",
    "                 num_filters,\n",
    "                 ):\n",
    "        \"\"\"Attributes of a convolutional neural network\n",
    "        - input (numpy array): a 2D or 3D matrix (height, width & depth) of an image\n",
    "        - stride (int): how many pixels to jump at a time when sliding\n",
    "        - zero_padding: boolean\n",
    "        - size: the size of the convolutional layer\n",
    "        \"\"\"\n",
    "        self.input = input\n",
    "        self.stride = stride\n",
    "        self.zero_padding = zero_padding\n",
    "        self.size = size\n",
    "        self.conv_layers = []\n",
    "        self.relu_layers = []\n",
    "        self.pooling_layers = []\n",
    "        \n",
    "    def add_conv_layer(self):\n",
    "        self.append(np.array((size, size, size)))\n",
    "        \n",
    "    def add_relu_layer(self):\n",
    "        \n",
    "    def add_pooling_layer(self):\n",
    "        \n",
    "    def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
